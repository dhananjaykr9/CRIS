# ðŸ›¡ï¸ CRIS â€” Customer Risk Intelligence System

**Predictive Analytics & Risk Classification Engine**

CRIS is a machine learning solution that predicts customer churn risk using a **SQL-First** architecture. It pushes heavy feature engineering into SQL Server, trains ML models in Python, and serves predictions through an interactive Streamlit dashboard.

---

## ðŸ—ï¸ Architecture

```
CSV Data â†’ SQL Server (Docker) â†’ SQL Feature Engineering â†’ Python ML â†’ Streamlit Dashboard
```

```mermaid
graph LR
    A[Raw CSVs] --> B[SQL Server]
    B --> C[Schema + Ingestion]
    C --> D[Target Engineering]
    D --> E[Feature Engineering<br>RFM / Trends / Ratios]
    E --> F[Python ML<br>LogReg / RF / XGBoost]
    F --> G[Streamlit Dashboard]
```

### Time-Aware Design
- **Observation Window**: Janâ€“Jun 2024 (feature computation)
- **Prediction Window**: Julâ€“Aug 2024 (churn labels)
- Zero data leakage â€” enforced via TDDQ tests

---

## ðŸ“ Project Structure

```
CRIS/
â”œâ”€â”€ docker-compose.yml          # SQL Server container
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ data/raw/                   # Synthetic CSV data
â”‚   â”œâ”€â”€ customers.csv           # 200 customers
â”‚   â”œâ”€â”€ orders.csv              # ~1000 orders
â”‚   â””â”€â”€ order_items.csv         # ~3000 items
â”œâ”€â”€ sql/
â”‚   â”œâ”€â”€ schema_creation.sql     # Table definitions (PK/FK)
â”‚   â”œâ”€â”€ target_engineering.sql  # Churn label generation
â”‚   â”œâ”€â”€ feature_eng.sql         # RFM + trend features (SQL view)
â”‚   â””â”€â”€ tests/                  # TDDQ assertion scripts
â”‚       â”œâ”€â”€ test_schema.sql
â”‚       â”œâ”€â”€ test_target_logic.sql
â”‚       â””â”€â”€ test_leakage.sql
â”œâ”€â”€ notebooks/
â”‚   â”œâ”€â”€ 01_eda.ipynb            # Exploratory analysis
â”‚   â””â”€â”€ 02_modeling.ipynb       # Training & evaluation
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ db_connector.py         # SQLAlchemy connection
â”‚   â”œâ”€â”€ data_ingestion.py       # CSV â†’ SQL pipeline
â”‚   â”œâ”€â”€ preprocessing.py        # Feature cleaning & splitting
â”‚   â”œâ”€â”€ inference.py            # Prediction engine
â”‚   â””â”€â”€ run_tddq.py            # Test runner
â”œâ”€â”€ app/
â”‚   â””â”€â”€ main.py                 # Streamlit dashboard
â”œâ”€â”€ models/                     # Serialized .pkl files
â””â”€â”€ README.md
```

---

## ðŸš€ Quick Start

### 1. Prerequisites
- Docker Desktop
- Python 3.9+
- ODBC Driver 17 for SQL Server

### 2. Start SQL Server
```bash
docker compose up -d
```
> **Note**: SQL Server is mapped to port **1434** to avoid conflicts with local instances.
> SA Password: `MyStr0ng!Passw0rd`

### 3. Install Dependencies
```bash
pip install -r requirements.txt
```

### 4. Ingest Data & Build Features
```bash
python src/data_ingestion.py
```

### 5. Run Data Quality Tests
```bash
python src/run_tddq.py
```

### 6. Train Models
Open and run `notebooks/02_modeling.ipynb` (or use `jupyter notebook`).

### 7. Launch Dashboard
```bash
streamlit run app/main.py
```

---

## ðŸ“Š Features Engineered (SQL)

| Feature | Type | Description |
|---------|------|-------------|
| `recency_days` | RFM | Days since last order |
| `frequency` | RFM | Total order count |
| `monetary` | RFM | Total spend |
| `avg_order_value_lifetime` | Trend | Avg order value (full window) |
| `avg_order_value_last_3m` | Trend | Avg order value (last 3 months) |
| `trend_ratio` | Trend | Recent vs lifetime spend ratio |
| `cancel_rate` | Ratio | Fraction of cancelled orders |
| `return_rate` | Ratio | Fraction of returned orders |
| `unique_categories` | Diversity | Product category count |
| `unique_products` | Diversity | Distinct product count |
| `avg_days_between_orders` | Regularity | Mean inter-order gap |

---

## ðŸ§ª TDDQ â€” Test-Driven Data Quality

| Test Suite | What It Validates |
|------------|-------------------|
| `test_schema.sql` | PK uniqueness, NOT NULL, FK integrity |
| `test_target_logic.sql` | Churn labels match temporal logic |
| `test_leakage.sql` | Features use only observation-window data |

---

## ðŸ¤– Models

| Model | Purpose |
|-------|---------|
| Logistic Regression | Baseline (interpretable) |
| Random Forest | Non-linear patterns |
| XGBoost | Gradient boosting (if installed) |

**Primary metric**: PR-AUC (handles class imbalance better than accuracy).

---

## ðŸŽ“ Key Technical Decisions

1. **SQL-First Feature Engineering** â€” Scales to BigQuery/Snowflake; features live in the DB, not Python scripts
2. **Time-Based Splitting** â€” No random `train_test_split` on transactional data
3. **TDDQ over Unit Tests** â€” Validates data quality at the source before modeling
4. **class_weight='balanced'** â€” Penalizes missing the minority (churn) class

---

## ðŸ“„ License

This project is for educational and portfolio purposes.
